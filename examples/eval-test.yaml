server_config: "./examples/server-config.json"

options:
  models: ["claude-3-haiku-20240307"]
  timeout: 30000
  max_steps: 3

tests:
  - name: "tool_understanding"
    description: "Verify that LLM understands available tools without calling them"
    prompt: "Please list all available tools and capabilities you have access to."
    expected_tool_calls:
      allowed: []
    response_scorers:
      - type: "regex"
        pattern: "(tool|function|capability|available)"
      - type: "llm-judge"
        criteria: "Did the assistant provide a comprehensive list of available tools without making any tool calls?"
        threshold: 0.8

  - name: "tool_with_parameters"
    description: "Test tool calls with specific parameters"
    prompt: "Please echo the message 'Hello from evaluation test'"
    expected_tool_calls:
      required: ["echo"]
    response_scorers:
      - type: "llm-judge"
        criteria: "Did the assistant call the echo tool with the correct message parameter?"
        threshold: 0.8

  - name: "selective_tool_usage"
    description: "Test that LLM uses only appropriate tools for the task"
    prompt: "Add the numbers 15 and 25 together"
    expected_tool_calls:
      required: ["add"]
      allowed: ["add"]
      prohibited: ["echo"]
    response_scorers:
      - type: "llm-judge"
        criteria: "Did the assistant successfully add the numbers using the add tool?"
        threshold: 0.7